<!doctype html><html lang=zh-cn itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Redis缓存相关面试题 - itning</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="itning"><meta name=description content="怎么保证redis是高并发以及高可用的？ Redis如何通过读写分离来承载读请求QPS超过10万+？ 一般来说 读高并发 而不是 写高并发 （读多写少）（写多读少最好用异步【消息队列】）
所以读写分离：主从架构 主负责写 从节点负责读
QPS太高可以直接增加从节点即可"><meta name=keywords content="itning,我们始终是路人,blog,java"><meta name=generator content="Hugo 0.68.1"><link rel=canonical href=https://blog.itning.top/post/2019/04/01/redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.af20b78e95c84de86b00a0242a4a77bd2601700e1b250edf27537d957ac0041d.css integrity="sha256-ryC3jpXITehrAKAkKkp3vSYBcA4bJQ7fJ1N9lXrABB0=" media=screen crossorigin=anonymous><meta property="og:title" content="Redis缓存相关面试题"><meta property="og:description" content="怎么保证redis是高并发以及高可用的？
Redis如何通过读写分离来承载读请求QPS超过10万+？
一般来说 读高并发 而不是 写高并发 （读多写少）（写多读少最好用异步【消息队列】）
所以读写分离：主从架构 主负责写 从节点负责读
QPS太高可以直接增加从节点即可"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.itning.top/post/2019/04/01/redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/"><meta property="article:published_time" content="2019-04-01T14:30:38+08:00"><meta property="article:modified_time" content="2019-04-01T14:30:38+08:00"><meta itemprop=name content="Redis缓存相关面试题"><meta itemprop=description content="怎么保证redis是高并发以及高可用的？
Redis如何通过读写分离来承载读请求QPS超过10万+？
一般来说 读高并发 而不是 写高并发 （读多写少）（写多读少最好用异步【消息队列】）
所以读写分离：主从架构 主负责写 从节点负责读
QPS太高可以直接增加从节点即可"><meta itemprop=datePublished content="2019-04-01T14:30:38+08:00"><meta itemprop=dateModified content="2019-04-01T14:30:38+08:00"><meta itemprop=wordCount content="549"><meta itemprop=keywords content="Redis,缓存,面试,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Redis缓存相关面试题"><meta name=twitter:description content="怎么保证redis是高并发以及高可用的？
Redis如何通过读写分离来承载读请求QPS超过10万+？
一般来说 读高并发 而不是 写高并发 （读多写少）（写多读少最好用异步【消息队列】）
所以读写分离：主从架构 主负责写 从节点负责读
QPS太高可以直接增加从节点即可"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>itning</a></div><div class=mobile-navbar-icon><span></span><span></span><span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://blog.itning.top/>主页</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://blog.itning.top/post/>归档</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://blog.itning.top/tags/>标签</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://blog.itning.top/categories/>分类</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://github.com/itning rel=noopener target=_blank>GitHub
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6C496.064 467.648 528.64 500.224 528.64 500.224 534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92.0.0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"/><path d="M841.152 457.152c-30.528.0-54.784 24.512-54.784 54.656V786.56H237.696V237.696h206.016c6.656.0 10.752.0 13.248.0C487.68 237.696 512 213.184 512 182.848 512 152.32 487.36 128 456.96 128H183.04C153.216 128 128 152.576 128 182.848c0 3.136.256 6.272.768 9.28C128.256 195.136 128 198.272 128 201.408v639.488c0 .064.0.192.0.256.0.128.0.192.0.32.0 30.528 24.512 54.784 54.784 54.784H829.76c6.592.0 9.728.0 11.712.0 28.736.0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344v-20.352V561.408 512.128C896 481.792 871.424 457.152 841.152 457.152z"/></svg></i></a></li></ul></nav><link href=https://cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.css rel=stylesheet><link href=https://cdn.bootcss.com/photoswipe/4.1.3/default-skin/default-skin.min.css rel=stylesheet><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>itning</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://blog.itning.top/>主页</a></li><li class=menu-item><a class=menu-item-link href=https://blog.itning.top/post/>归档</a></li><li class=menu-item><a class=menu-item-link href=https://blog.itning.top/tags/>标签</a></li><li class=menu-item><a class=menu-item-link href=https://blog.itning.top/categories/>分类</a></li><li class=menu-item><a class=menu-item-link href=https://github.com/itning rel=noopener target=_blank>GitHub
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6C496.064 467.648 528.64 500.224 528.64 500.224 534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92.0.0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"/><path d="M841.152 457.152c-30.528.0-54.784 24.512-54.784 54.656V786.56H237.696V237.696h206.016c6.656.0 10.752.0 13.248.0C487.68 237.696 512 213.184 512 182.848 512 152.32 487.36 128 456.96 128H183.04C153.216 128 128 152.576 128 182.848c0 3.136.256 6.272.768 9.28C128.256 195.136 128 198.272 128 201.408v639.488c0 .064.0.192.0.256.0.128.0.192.0.32.0 30.528 24.512 54.784 54.784 54.784H829.76c6.592.0 9.728.0 11.712.0 28.736.0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344v-20.352V561.408 512.128C896 481.792 871.424 457.152 841.152 457.152z"/></svg></i></a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>Redis缓存相关面试题</h1><div class=post-meta><time datetime=2019-04-01 class=post-time>2019年04月01日 14:30:38</time><div class=post-category><a href=https://blog.itning.top/categories/redis/>Redis</a></div><span class=more-meta>约 549 字</span>
<span class=more-meta>预计阅读 3 分钟</span>
<span id=busuanzi_container_page_pv>| 阅读 <span id=busuanzi_value_page_pv></span></span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>文章目录</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#怎么保证redis是高并发以及高可用的>怎么保证redis是高并发以及高可用的？</a><ul><li><a href=#redis如何通过读写分离来承载读请求qps超过10万>Redis如何通过读写分离来承载读请求QPS超过10万+？</a></li><li><a href=#redis-replication以及master持久化对主从架构的安全意义>Redis replication以及master持久化对主从架构的安全意义</a></li><li><a href=#redis主从复制原理断点续传无磁盘化复制过期key处理>Redis主从复制原理、断点续传、无磁盘化复制、过期key处理</a></li><li><a href=#redis-replication的完整流运行程和原理的再次深入剖析>Redis Replication的完整流运行程和原理的再次深入剖析</a></li><li><a href=#redis哨兵>Redis哨兵</a></li><li><a href=#redis哨兵主备切换的数据丢失问题异步复制集群脑裂>Redis哨兵主备切换的数据丢失问题：异步复制、集群脑裂</a></li><li><a href=#redis哨兵的多个核心底层原理的深入解析包含slave选举算法>Redis哨兵的多个核心底层原理的深入解析（包含slave选举算法）</a></li></ul></li><li><a href=#怎么保证redis挂掉之后再重启数据可以进行恢复>怎么保证redis挂掉之后再重启数据可以进行恢复？</a><ul><li><a href=#为什么要做持久化>为什么要做持久化？</a></li><li><a href=#rdb与aof>RDB与AOF</a></li></ul></li><li><a href=#redis-cluster集群模式的原理>Redis Cluster集群模式的原理</a><ul><li><a href=#节点间的内部通信机制>节点间的内部通信机制</a></li><li><a href=#面向集群的jedis内部实现原理>面向集群的jedis内部实现原理</a></li><li><a href=#高可用性与主备切换原理>高可用性与主备切换原理</a></li></ul></li></ul></nav></div></div><div class=post-content><h2 id=怎么保证redis是高并发以及高可用的>怎么保证redis是高并发以及高可用的？</h2><h3 id=redis如何通过读写分离来承载读请求qps超过10万>Redis如何通过读写分离来承载读请求QPS超过10万+？</h3><p>一般来说 读高并发 而不是 写高并发 （读多写少）（写多读少最好用异步【消息队列】）</p><p>所以读写分离：主从架构 主负责写 从节点负责读</p><p>QPS太高可以直接增加从节点即可</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a1.png alt=主从分离></p><h3 id=redis-replication以及master持久化对主从架构的安全意义>Redis replication以及master持久化对主从架构的安全意义</h3><p>如果master不做持久化（关闭RDB和AOF）当master宕机重启的时候，master没有任何数据可以恢复，那么它会将空数据同步到slave节点中，相当于清空了slave节点。</p><p>所以必须要使用持久化机制</p><h3 id=redis主从复制原理断点续传无磁盘化复制过期key处理>Redis主从复制原理、断点续传、无磁盘化复制、过期key处理</h3><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a2.png alt=RedisReplica最最基本的原理></p><p>1、主从架构的核心原理</p><p>当启动一个slave node的时候，它会发送一个PSYNC命令给master node</p><p>如果这是slave node重新连接master node，那么master node仅仅会复制给slave部分缺少的数据; 否则如果是slave node第一次连接master node，那么会触发一次full resynchronization</p><p>开始full resynchronization的时候，master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。RDB文件生成完毕之后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中。然后master会将内存中缓存的写命令发送给slave，slave也会同步这些数据。</p><p>slave node如果跟master node有网络故障，断开了连接，会自动重连。master如果发现有多个slave node都来重新连接，仅仅会启动一个rdb save操作，用一份数据服务所有slave node。</p><p>2、主从复制的断点续传</p><p>从redis 2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份</p><p>master node会在内存中常见一个backlog，master和slave都会保存一个replica offset还有一个master id，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制</p><p>但是如果没有找到对应的offset，那么就会执行一次resynchronization</p><p>3、无磁盘化复制</p><p>master在内存中直接创建rdb，然后发送给slave，不会在自己本地落地磁盘了</p><p>repl-diskless-sync
repl-diskless-sync-delay，等待一定时长再开始复制，因为要等更多slave重新连接过来</p><p>4、过期key处理</p><p>slave不会过期key，只会等待master过期key。如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a3.png alt=Redis主从复制的原理></p><h3 id=redis-replication的完整流运行程和原理的再次深入剖析>Redis Replication的完整流运行程和原理的再次深入剖析</h3><p>1、复制的完整流程</p><p>（1）slave node启动，仅仅保存master node的信息，包括master node的host和ip，但是复制流程没开始</p><p>master host和ip是从哪儿来的，redis.conf里面的slaveof配置的</p><p>（2）slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，如果发现，就跟master node建立socket网络连接
（3）slave node发送ping命令给master node
（4）口令认证，如果master设置了requirepass，那么salve node必须发送masterauth的口令过去进行认证
（5）master node第一次执行全量复制，将所有数据发给slave node
（6）master node后续持续将写命令，异步复制给slave node</p><p>2、数据同步相关的核心机制</p><p>指的就是第一次slave连接msater的时候，执行的全量复制，那个过程里面你的一些细节的机制</p><p>（1）master和slave都会维护一个offset</p><p>master会在自身不断累加offset，slave也会在自身不断累加offset
slave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset</p><p>这个倒不是说特定就用在全量复制的，主要是master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况</p><p>（2）backlog</p><p>master node有一个backlog，默认是1MB大小
master node给slave node复制数据时，也会将数据在backlog中同步写一份
backlog主要是用来做全量复制中断候的增量复制的</p><p>（3）master run id</p><p>info server，可以看到master run id
如果根据host+ip定位master node，是不靠谱的，如果master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分，run id不同就做全量复制
如果需要不更改run id重启redis，可以使用redis-cli debug reload命令</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a4.png alt=RedisRunId></p><p>（4）psync</p><p>从节点使用psync从master node进行复制，psync runid offset
master node会根据自身的情况返回响应信息，可能是FULLRESYNC runid offset触发全量复制，可能是CONTINUE触发增量复制</p><p>3、全量复制</p><p>（1）master执行bgsave，在本地生成一份rdb快照文件
（2）master node将rdb快照文件发送给salve node，如果rdb复制时间超过60秒（repl-timeout），那么slave node就会认为复制失败，可以适当调节大这个参数
（3）对于千兆网卡的机器，一般每秒传输100MB，6G文件，很可能超过60s
（4）master node在生成rdb时，会将所有新的写命令缓存在内存中，在salve node保存了rdb之后，再将新的写命令复制给salve node
（5）client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败
（6）slave node接收到rdb之后，清空自己的旧数据，然后重新加载rdb到自己的内存中，同时基于旧的数据版本对外提供服务
（7）如果slave node开启了AOF，那么会立即执行BGREWRITEAOF，重写AOF</p><p>rdb生成、rdb通过网络拷贝、slave旧数据的清理、slave aof rewrite，很耗费时间</p><p>如果复制的数据量在4G~6G之间，那么很可能全量复制时间消耗到1分半到2分钟</p><p>4、增量复制</p><p>（1）如果全量复制过程中，master-slave网络连接断掉，那么salve重新连接master时，会触发增量复制
（2）master直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认backlog就是1MB
（3）msater就是根据slave发送的psync中的offset来从backlog中获取数据的</p><p>5、heartbeat</p><p>主从节点互相都会发送heartbeat信息</p><p>master默认每隔10秒发送一次heartbeat，salve node每隔1秒发送一个heartbeat</p><p>6、异步复制</p><p>master每次接收到写命令之后，现在内部写入数据，然后异步发送给slave node</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a5.png alt=复制的完整的基本流程></p><h3 id=redis哨兵>Redis哨兵</h3><p>1、哨兵的介绍</p><p>sentinal，中文名是哨兵</p><p>哨兵是redis集群架构中非常重要的一个组件，主要功能如下</p><p>（1）集群监控，负责监控redis master和slave进程是否正常工作
（2）消息通知，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员
（3）故障转移，如果master node挂掉了，会自动转移到slave node上
（4）配置中心，如果故障转移发生了，通知client客户端新的master地址</p><p>哨兵本身也是分布式的，作为一个哨兵集群去运行，互相协同工作</p><p>（1）故障转移时，判断一个master node是宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题
（2）即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的，那就很坑爹了</p><p>目前采用的是sentinal 2版本，sentinal 2相对于sentinal 1来说，重写了很多代码，主要是让故障转移的机制和算法变得更加健壮和简单</p><p>2、哨兵的核心知识</p><p>（1）哨兵至少需要3个实例，来保证自己的健壮性
（2）哨兵 + redis主从的部署架构，是不会保证数据零丢失的，只能保证redis集群的高可用性
（3）对于哨兵 + redis主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练</p><p>3、为什么redis哨兵集群只有2个节点无法正常工作？</p><p>哨兵集群必须部署2个以上节点</p><p>如果哨兵集群仅仅部署了个2个哨兵实例，quorum=1</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>+----+         +----+
| M1 |---------| R1 |
| S1 |         | S2 |
+----+         +----+
</code></pre></td></tr></table></div></div><p>Configuration: quorum = 1</p><p>master宕机，s1和s2中只要有1个哨兵认为master宕机就可以还行切换，同时s1和s2中会选举出一个哨兵来执行故障转移</p><p>同时这个时候，需要majority，也就是大多数哨兵都是运行的，2个哨兵的majority就是2（2的majority=2，3的majority=2，5的majority=3，4的majority=2），2个哨兵都运行着，就可以允许执行故障转移</p><p>但是如果整个M1和S1运行的机器宕机了，那么哨兵只有1个了，此时就没有majority来允许执行故障转移，虽然另外一台机器还有一个R1，但是故障转移不会执行</p><p>4、经典的3节点哨兵集群</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre class=chroma><code class=language-fallback data-lang=fallback>       +----+
       | M1 |
       | S1 |
       +----+
          |
+----+    |    +----+
| R2 |----+----| R3 |
| S2 |         | S3 |
+----+         +----+
</code></pre></td></tr></table></div></div><p>Configuration: quorum = 2，majority</p><p>如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机，然后选举出一个来执行故障转移</p><p>同时3个哨兵的majority是2，所以还剩下的2个哨兵运行着，就可以允许执行故障转移</p><h3 id=redis哨兵主备切换的数据丢失问题异步复制集群脑裂>Redis哨兵主备切换的数据丢失问题：异步复制、集群脑裂</h3><p>1、两种数据丢失的情况</p><p>主备切换的过程，可能会导致数据丢失</p><p>（1）异步复制导致的数据丢失</p><p>因为master -> slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了，此时这些部分数据就丢失了</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a6.png alt=异步复制导致的数据丢失></p><p>（2）脑裂导致的数据丢失</p><p>脑裂，也就是说，某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着</p><p>此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master</p><p>这个时候，集群里就会有两个master，也就是所谓的脑裂</p><p>此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master的数据可能也丢失了</p><p>因此旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会清空，重新从新的master复制数据</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a7.png alt=脑裂导致的数据丢失></p><hr><p>2、解决异步复制和脑裂导致的数据丢失</p><p>min-slaves-to-write 1
min-slaves-max-lag 10</p><p>要求至少有1个slave，数据复制和同步的延迟不能超过10秒</p><p>如果说一旦所有的slave，数据复制和同步的延迟都超过了10秒钟，那么这个时候，master就不会再接收任何请求了</p><p>上面两个配置可以减少异步复制和脑裂导致的数据丢失</p><p>（1）减少异步复制的数据丢失</p><p>有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低的可控范围内</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a8.png alt=减少异步复制的数据丢失></p><p>（2）减少脑裂的数据丢失</p><p>如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给自己ack消息，那么就直接拒绝客户端的写请求</p><p>这样脑裂后的旧master就不会接受client的新数据，也就避免了数据丢失</p><p>上面的配置就确保了，如果跟任何一个slave丢了连接，在10秒后发现没有slave给自己ack，那么就拒绝新的写请求</p><p>因此在脑裂场景下，最多就丢失10秒的数据</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a9.png alt=减少脑裂的数据丢失></p><h3 id=redis哨兵的多个核心底层原理的深入解析包含slave选举算法>Redis哨兵的多个核心底层原理的深入解析（包含slave选举算法）</h3><p>1、sdown和odown转换机制</p><p>sdown和odown两种失败状态</p><p>sdown是主观宕机，就一个哨兵如果自己觉得一个master宕机了，那么就是主观宕机</p><p>odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机</p><p>sdown达成的条件很简单，如果一个哨兵ping一个master，超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机</p><p>sdown到odown转换的条件很简单，如果一个哨兵在指定时间内，收到了quorum指定数量的其他哨兵也认为那个master是sdown了，那么就认为是odown了，客观认为master宕机</p><p>2、哨兵集群的自动发现机制</p><p>哨兵互相之间的发现，是通过redis的pub/sub系统实现的，每个哨兵都会往__sentinel__:hello这个channel里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知到其他的哨兵的存在</p><p>每隔两秒钟，每个哨兵都会往自己监控的某个master+slaves对应的__sentinel__:hello channel里发送一个消息，内容是自己的host、ip和runid还有对这个master的监控配置</p><p>每个哨兵也会去监听自己监控的每个master+slaves对应的__sentinel__:hello channel，然后去感知到同样在监听这个master+slaves的其他哨兵的存在</p><p>每个哨兵还会跟其他哨兵交换对master的监控配置，互相进行监控配置的同步</p><p>3、slave配置的自动纠正</p><p>哨兵会负责自动纠正slave的一些配置，比如slave如果要成为潜在的master候选人，哨兵会确保slave在复制现有master的数据; 如果slave连接到了一个错误的master上，比如故障转移之后，那么哨兵会确保它们连接到正确的master上</p><p>4、slave->master选举算法</p><p>如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个slave来</p><p>会考虑slave的一些信息</p><p>（1）跟master断开连接的时长
（2）slave优先级
（3）复制offset
（4）run id</p><p>如果一个slave跟master断开连接已经超过了down-after-milliseconds的10倍，外加master宕机的时长，那么slave就被认为不适合选举为master</p><p>(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state</p><p>接下来会对slave进行排序</p><p>（1）按照slave优先级进行排序，slave priority越低，优先级就越高
（2）如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高
（3）如果上面两个条件都相同，那么选择一个run id比较小的那个slave</p><p>5、quorum和majority</p><p>每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还得得到majority哨兵的授权，才能正式执行切换</p><p>如果quorum &lt; majority，比如5个哨兵，majority就是3，quorum设置为2，那么就3个哨兵授权就可以执行切换</p><p>但是如果quorum >= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵，quorum是5，那么必须5个哨兵都同意授权，才能执行切换</p><p>6、configuration epoch</p><p>哨兵会对一套redis master+slave进行监控，有相应的监控的配置</p><p>执行切换的那个哨兵，会从要切换到的新master（salve->master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一的</p><p>如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configuration epoch，作为新的version号</p><p>7、configuraiton传播</p><p>哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵，就是通过之前说的pub/sub消息机制</p><p>这里之前的version号就很重要了，因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的</p><p>其他的哨兵都是根据版本号的大小来更新自己的master配置的</p><h2 id=怎么保证redis挂掉之后再重启数据可以进行恢复>怎么保证redis挂掉之后再重启数据可以进行恢复？</h2><h3 id=为什么要做持久化>为什么要做持久化？</h3><p>如果没有持久化的话，redis遇到灾难性故障的时候，就会丢失所有的数据</p><p>如果通过持久化将数据搞一份儿在磁盘上去，然后定期比如说同步和备份到一些云存储服务上去，那么就可以保证数据不丢失全部，还是可以恢复一部分数据回来的</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a10.png alt=redis持久化的意义></p><h3 id=rdb与aof>RDB与AOF</h3><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a11.png alt=RDB和AOF的介绍></p><p>1、RDB和AOF两种持久化机制的介绍</p><p>RDB持久化机制，对redis中的数据执行周期性的持久化</p><p>AOF机制对每条写入命令作为日志，以append-only的模式写入一个日志文件中，在redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集</p><p>如果我们想要redis仅仅作为纯内存的缓存来用，那么可以禁止RDB和AOF所有的持久化机制</p><p>通过RDB或AOF，都可以将redis内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云，云服务</p><p>如果redis挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动redis，redis就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务</p><p>如果同时使用RDB和AOF两种持久化机制，那么在redis重启的时候，会使用AOF来重新构建数据，因为AOF中的数据更加完整</p><hr><p>2、RDB持久化机制的优点</p><p>（1）RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说Amazon的S3云服务上去，在国内可以是阿里云的ODPS分布式存储上，以预定好的备份策略来定期备份redis中的数据</p><p>（2）RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可</p><p>（3）相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速</p><hr><p>3、RDB持久化机制的缺点</p><p>（1）如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据</p><p>（2）RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒</p><hr><p>4、AOF持久化机制的优点</p><p>（1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据</p><p>（2）AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复</p><p>（3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。</p><p>（4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据</p><hr><p>5、AOF持久化机制的缺点</p><p>（1）对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大</p><p>（2）AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的</p><p>（3）以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似AOF这种较为复杂的基于命令日志/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有bug。不过AOF就是为了避免rewrite过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a12.png alt=rewrite原理剖析></p><hr><p>6、RDB和AOF到底该如何选择</p><p>（1）不要仅仅使用RDB，因为那样会导致你丢失很多数据</p><p>（2）也不要仅仅使用AOF，因为那样有两个问题，第一，你通过AOF做冷备，没有RDB做冷备，来的恢复速度更快; 第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug</p><p>（3）综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a13.png alt=RDB丢失数据的问题></p><h2 id=redis-cluster集群模式的原理>Redis Cluster集群模式的原理</h2><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a14.png alt=redis单master架构的容量的瓶颈问题></p><p>支撑N个redis master node，每个master node都可以挂载多个slave node</p><p>读写分离的架构，对于每个master来说，写就写到master，然后读就从mater对应的slave去读</p><p>高可用，因为每个master都有salve节点，那么如果mater挂掉，redis cluster这套机制，就会自动将某个slave切换成master</p><p>redis cluster（多master + 读写分离 + 高可用）</p><p>我们只要基于redis cluster去搭建redis集群即可，不需要手工去搭建replication复制+主从架构+读写分离+哨兵集群+高可用</p><p>redis cluster vs. replication + sentinal</p><p>如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个G，单机足够了</p><p>replication，一个mater，多个slave，要几个slave跟你的要求的读吞吐量有关系，然后自己搭建一个sentinal集群，去保证redis主从架构的高可用性，就可以了</p><p>redis cluster，主要是针对海量数据+高并发+高可用的场景，海量数据，如果你的数据量很大，那么建议就用redis cluster</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a15.png alt=redis如何通过master横向扩容支撑1T+数据量></p><h3 id=节点间的内部通信机制>节点间的内部通信机制</h3><p>1、基础通信原理</p><p>（1）redis cluster节点间采取gossip协议进行通信</p><p>跟集中式不同，不是将集群元数据（节点信息，故障，等等）集中存储在某个节点上，而是互相之间不断通信，保持整个集群所有节点的数据是完整的</p><p>维护集群的元数据用得，集中式，一种叫做gossip</p><p>集中式：好处在于，元数据的更新和读取，时效性非常好，一旦元数据出现了变更，立即就更新到集中式的存储中，其他节点读取的时候立即就可以感知到; 不好在于，所有的元数据的跟新压力全部集中在一个地方，可能会导致元数据的存储有压力</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a16.png alt=集中式的集群元数据存储和维护></p><p>gossip：好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力; 缺点，元数据更新有延时，可能导致集群的一些操作会有一些滞后</p><p>我们刚才做reshard，去做另外一个操作，会发现说，configuration error，达成一致</p><p><img src=/images/2019-04-01-Redis%E7%BC%93%E5%AD%98%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/a17.png alt=gossip协议维护集群元数据></p><p>（2）10000端口</p><p>每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如7001，那么用于节点间通信的就是17001端口</p><p>每隔节点每隔一段时间都会往另外几个节点发送ping消息，同时其他几点接收到ping之后返回pong</p><p>（3）交换的信息</p><p>故障信息，节点的增加和移除，hash slot信息，等等</p><p>2、gossip协议</p><p>gossip协议包含多种消息，包括ping，pong，meet，fail，等等</p><p>meet: 某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信</p><p>redis-trib.rb add-node</p><p>其实内部就是发送了一个gossip meet消息，给新加入的节点，通知那个节点去加入我们的集群</p><p>ping: 每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据</p><p>每个节点每秒都会频繁发送ping给其他的集群，ping，频繁的互相之间交换数据，互相进行元数据的更新</p><p>pong: 返回ping和meet，包含自己的状态和其他信息，也可以用于信息广播和更新</p><p>fail: 某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了</p><p>3、ping消息深入</p><p>ping很频繁，而且要携带一些元数据，所以可能会加重网络负担</p><p>每个节点每秒会执行10次ping，每次会选择5个最久没有通信的其他节点</p><p>当然如果发现某个节点通信延时达到了cluster_node_timeout / 2，那么立即发送ping，避免数据交换延时过长，落后的时间太长了</p><p>比如说，两个节点之间都10分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题</p><p>所以cluster_node_timeout可以调节，如果调节比较大，那么会降低发送的频率</p><p>每次ping，一个是带上自己节点的信息，还有就是带上1/10其他节点的信息，发送出去，进行数据交换</p><p>至少包含3个其他节点的信息，最多包含总节点-2个其他节点的信息</p><h3 id=面向集群的jedis内部实现原理>面向集群的jedis内部实现原理</h3><p>开发，jedis，redis的java client客户端，redis cluster，jedis cluster api</p><p>jedis cluster api与redis cluster集群交互的一些基本原理</p><p>1、基于重定向的客户端</p><p>redis-cli -c，自动重定向</p><p>（1）请求重定向</p><p>客户端可能会挑选任意一个redis实例去发送命令，每个redis实例接收到命令，都会计算key对应的hash slot</p><p>如果在本地就在本地处理，否则返回moved给客户端，让客户端进行重定向</p><p>cluster keyslot mykey，可以查看一个key对应的hash slot是什么</p><p>用redis-cli的时候，可以加入-c参数，支持自动的请求重定向，redis-cli接收到moved之后，会自动重定向到对应的节点执行命令</p><p>（2）计算hash slot</p><p>计算hash slot的算法，就是根据key计算CRC16值，然后对16384取模，拿到对应的hash slot</p><p>用hash tag可以手动指定key对应的slot，同一个hash tag下的key，都会在一个hash slot中，比如set mykey1:{100}和set mykey2:{100}</p><p>（3）hash slot查找</p><p>节点间通过gossip协议进行数据交换，就知道每个hash slot在哪个节点上</p><p>2、smart jedis</p><p>（1）什么是smart jedis</p><p>基于重定向的客户端，很消耗网络IO，因为大部分情况下，可能都会出现一次请求重定向，才能找到正确的节点</p><p>所以大部分的客户端，比如java redis客户端，就是jedis，都是smart的</p><p>本地维护一份hashslot -> node的映射表，缓存，大部分情况下，直接走本地缓存就可以找到hashslot -> node，不需要通过节点进行moved重定向</p><p>（2）JedisCluster的工作原理</p><p>在JedisCluster初始化的时候，就会随机选择一个node，初始化hashslot -> node映射表，同时为每个节点创建一个JedisPool连接池</p><p>每次基于JedisCluster执行操作，首先JedisCluster都会在本地计算key的hashslot，然后在本地映射表找到对应的节点</p><p>如果那个node正好还是持有那个hashslot，那么就ok; 如果说进行了reshard这样的操作，可能hashslot已经不在那个node上了，就会返回moved</p><p>如果JedisCluter API发现对应的节点返回moved，那么利用该节点的元数据，更新本地的hashslot -> node映射表缓存</p><p>重复上面几个步骤，直到找到对应的节点，如果重试超过5次，那么就报错，JedisClusterMaxRedirectionException</p><p>jedis老版本，可能会出现在集群某个节点故障还没完成自动切换恢复时，频繁更新hash slot，频繁ping节点检查活跃，导致大量网络IO开销</p><p>jedis最新版本，对于这些过度的hash slot更新和ping，都进行了优化，避免了类似问题</p><p>（3）hashslot迁移和ask重定向</p><p>如果hash slot正在迁移，那么会返回ask重定向给jedis</p><p>jedis接收到ask重定向之后，会重新定位到目标节点去执行，但是因为ask发生在hash slot迁移过程中，所以JedisCluster API收到ask是不会更新hashslot本地缓存</p><p>已经可以确定说，hashslot已经迁移完了，moved是会更新本地hashslot->node映射表缓存的</p><h3 id=高可用性与主备切换原理>高可用性与主备切换原理</h3><p>redis cluster的高可用的原理，几乎跟哨兵是类似的</p><p>1、判断节点宕机</p><p>如果一个节点认为另外一个节点宕机，那么就是pfail，主观宕机</p><p>如果多个节点都认为另外一个节点宕机了，那么就是fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown</p><p>在cluster-node-timeout内，某个节点一直没有返回pong，那么就被认为pfail</p><p>如果一个节点认为某个节点pfail了，那么会在gossip ping消息中，ping给其他节点，如果超过半数的节点都认为pfail了，那么就会变成fail</p><p>2、从节点过滤</p><p>对宕机的master node，从其所有的slave node中，选择一个切换成master node</p><p>检查每个slave node与master node断开连接的时间，如果超过了cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成master</p><p>这个也是跟哨兵是一样的，从节点超时过滤的步骤</p><p>3、从节点选举</p><p>哨兵：对所有从节点进行排序，slave priority，offset，run id</p><p>每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举</p><p>所有的master node开始slave选举投票，给要进行选举的slave进行投票，如果大部分master node（N/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成master</p><p>从节点执行主备切换，从节点切换为主节点</p><p>4、与哨兵比较</p><p>整个流程跟哨兵相比，非常类似，所以说，redis cluster功能强大，直接集成了replication和sentinal的功能</p><p>没有办法去给大家深入讲解redis底层的设计的细节，核心原理和设计的细节，那个除非单独开一门课，redis底层原理深度剖析，redis源码</p><p>对于咱们这个架构课来说，主要关注的是架构，不是底层的细节，对于架构来说，核心的原理的基本思路，是要梳理清晰的</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>文章作者</span>
<span class=item-content>itning</span></p><p class=copyright-item><span class=item-title>上次更新</span>
<span class=item-content>2019年04月01日 14:30:38</span></p><p class=copyright-item><span class=item-title>许可协议</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=https://blog.itning.top/tags/redis/>Redis</a>
<a href=https://blog.itning.top/tags/%E7%BC%93%E5%AD%98/>缓存</a>
<a href=https://blog.itning.top/tags/%E9%9D%A2%E8%AF%95/>面试</a></div><nav class=post-nav><a class=prev href=/post/2019/04/08/%E5%8D%95%E7%82%B9%E7%99%BB%E5%BD%95sso%E5%92%8C%E9%9B%86%E4%B8%AD%E5%BC%8F%E8%AE%A4%E8%AF%81%E6%9C%8D%E5%8A%A1cas%E5%92%8C%E5%BC%80%E6%94%BE%E6%8E%88%E6%9D%83oauth%E7%9A%84%E7%AE%80%E8%A6%81%E8%A7%A3%E9%87%8A/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">单点登录SSO和集中式认证服务CAS和开放授权OAuth的简要解释</span>
<span class="prev-text nav-mobile">上一篇</span></a>
<a class=next href=/post/2019/03/31/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%8E%9F%E7%90%86%E5%8F%8A%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9B%B8%E5%85%B3%E9%9D%A2%E8%AF%95%E9%A2%98/><span class="next-text nav-default">分库分表原理及中间件相关面试题</span>
<span class="prev-text nav-mobile">下一篇</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"/></svg></i></a></nav></footer></article><div class="post bg-white"><script src=https://utteranc.es/client.js repo=itning/blog issue-term=pathname theme=github-light crossorigin=anonymous async></script></div></div></div></main><footer id=footer class=footer><div class=icon-links><a href=mailto:itning@itning.top rel="me noopener" class=iconfont title=email><svg class="icon" viewBox="0 0 1451 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408 1361.641813S1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523L83.726336 1024H682.532949 753.579947 1348.948139L1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955C777.248 802.205449 742.347691 811.03081 718.063616 811.603883z"/></svg></a><a href=http://github.com/itning rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=https://blog.itning.top/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=copyright-year>&copy;
2016 -
2020
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>itning
</span><script type=text/javascript>document.write(unescape("%3Cspan id='cnzz_stat_icon_1278714977'%3E%3C/span%3E%3Cscript src='https://v1.cnzz.com/z_stat.php%3Fid%3D1278714977%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));</script></span><span id=busuanzi_container>访客数/访问量：<span id=busuanzi_value_site_uv></span>/<span id=busuanzi_value_site_pv></span></span>
<span>黑ICP备17003448号</span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script src=https://cdn.bootcss.com/jquery/3.2.1/jquery.min.js></script><script src=https://cdn.bootcss.com/slideout/1.0.1/slideout.min.js></script><script type=text/javascript src=/js/main.dee43230127a73d039a734510fa896c89c3c7ce0cf0be0c7a7433f8fd69b76dc.js crossorigin=anonymous></script><script type=text/javascript src=/js/load-photoswipe.js></script><script src=https://cdn.bootcss.com/photoswipe/4.1.3/photoswipe.min.js></script><script src=https://cdn.bootcss.com/photoswipe/4.1.3/photoswipe-ui-default.min.js></script><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script></body></html>